{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba5b461",
   "metadata": {},
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c317b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a349a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./fig/puppy.bmp')\n",
    "if src is None:\n",
    "    print('image read failed')\n",
    "    sys.exit()\n",
    "    \n",
    "M = np.array([[1,0.2,100],\n",
    "             [0,1,100]], dtype=np.float32)\n",
    "dst = cv2.warpAffine(src, M, (0,0))\n",
    "dst_resize = cv2.resize(src, (0,0), fx=2, fy=1,\n",
    "                       interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.imshow('resize', dst_resize)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5921ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "src = cv2.imread('./fig/puppy.bmp')\n",
    "if src is None:\n",
    "    print('image read failed')\n",
    "    sys.exit()\n",
    "print(src.shape)\n",
    "h, w = src.shape[:2]\n",
    "cp = (w/2, h/2)\n",
    "M = cv2.getRotationMatrix2D(cp,30,1)\n",
    "\n",
    "dst = cv2.warpAffine(src, M, (0,0))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d52b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./fig/checkerboard.png')\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "\n",
    "src_point = np.array([[217,50], [691,47], [830,517], [67,526]],np.float32)\n",
    "dst_point = np.array([[0,0], [w-1,0],[w-1,h-1],[0,h-1]],np.float32)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src_point, dst_point)\n",
    "dst = cv2.warpPerspective(src, M, (w,h))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b91cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./fig/blue_eyes.png', cv2.IMREAD_REDUCED_COLOR_2)\n",
    "\n",
    "# kernel_3 = np.ones((3,3), np.float32)/9\n",
    "# kernel_5 = np.ones((5,5), np.float32)/25\n",
    "\n",
    "# dst3 = cv2.filter2D(src, -1, kernel_3)\n",
    "# dst5 = cv2.filter2D(src, -1, kernel_5)\n",
    "\n",
    "dst3 = cv2.blur(src, (3,3))\n",
    "dst5 = cv2.blur(src, (5,5))\n",
    "\n",
    "dst_gaussian = cv2.GaussianBlur(src, (0,0), 1)\n",
    "dst_bilateral = cv2.bilateralFilter(src, -1, 1,1)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst3', dst3)\n",
    "cv2.imshow('dst5', dst5)\n",
    "cv2.imshow('dst_gaussian', dst_gaussian)\n",
    "cv2.imshow('dst_bilateral', dst_bilateral)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "324eb9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./fig/spring_in_park.jpg', cv2.IMREAD_REDUCED_COLOR_2)\n",
    "if src is None:\n",
    "    print('image read failed')\n",
    "    sys.exit()\n",
    "src_hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "h,s,v = cv2.split(src_hsv)\n",
    "\n",
    "v_equal = cv2.equalizeHist(v)\n",
    "v_norm = cv2.normalize(v, None, 0,255, cv2.NORM_MINMAX)\n",
    "\n",
    "src_equal = cv2.merge((h,s,v_equal))\n",
    "src_norm = cv2.merge((h,s,v_norm))\n",
    "\n",
    "equal = cv2.cvtColor(src_equal, cv2.COLOR_HSV2BGR)\n",
    "norm = cv2.cvtColor(src_norm, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('equal', equal)\n",
    "cv2.imshow('norm', norm)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f6b889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_track(pos):\n",
    "    hmin = cv2.getTrackbarPos('min','src')\n",
    "    hmax = cv2.getTrackbarPos('max','src')\n",
    "    dst = cv2.inRange(src_hsv, (hmin,150,0), (hmax,255,255))\n",
    "    cv2.imshow('src', dst)\n",
    "\n",
    "src = cv2.imread('./fig/palette_round.jpg')\n",
    "src_hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.createTrackbar('min', 'src', 0, 179, call_track)\n",
    "cv2.createTrackbar('max', 'src', 1, 179, call_track)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c111f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./fig/green.png', cv2.IMREAD_REDUCED_COLOR_2)\n",
    "\n",
    "src_ycrcb = cv2.cvtColor(src, cv2.COLOR_BGR2YCR_CB)\n",
    "\n",
    "x,y,w,h = cv2.selectROI(src)\n",
    "crop = src_ycrcb[y:y+h, x:x+w]\n",
    "\n",
    "channels = [1,2]\n",
    "ranges = [0,256, 0,256]\n",
    "hist = cv2.calcHist([crop],channels,None,[256,256],ranges)\n",
    "backproj = cv2.calcBackProject([src_ycrcb],channels,hist,ranges,1)\n",
    "dst = cv2.copyTo(src, backproj)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('backproj', backproj)\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942500b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed')\n",
    "    sys.exit()\n",
    "    \n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS)*0.7)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"DIVX\")\n",
    "\n",
    "out = cv2.VideoWriter('output.avi', fourcc, fps, (w,h))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video read failed\")\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    out.write(frame)\n",
    "    \n",
    "    kw = cv2.waitKey(30)\n",
    "    if kw==27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64cec0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_mouse(event, x,y, flags, params):\n",
    "    global oldx, oldy\n",
    "    if event==cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x,y\n",
    "    elif event==cv2.EVENT_MOUSEMOVE:\n",
    "        if flags&cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.line(img, (oldx,oldy), (x,y), (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.imshow('img', img)\n",
    "            oldx,oldy = x,y\n",
    "            \n",
    "img = np.ones((500,600,3), np.uint8)*255\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.setMouseCallback('img', call_mouse)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf5b90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./fig/puppy.bmp')\n",
    "if img is None:\n",
    "    print('image read failed')\n",
    "    sys.exit()\n",
    "    \n",
    "cv2.namedWindow('image', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "while True:\n",
    "    kw = cv2.waitKey()\n",
    "    if kw==27 or kw==ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608ede1",
   "metadata": {},
   "source": [
    "# DNN\n",
    "## image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd57f9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple1.png', 'apple2.png', 'beagle.jpg', 'fish.jpg', 'pineapple.jpg', 'scooter.jpg', 'space_shuttle.jpg']\n",
      "(366, 640, 3)\n",
      "Network load complete\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "filename = './googlenet/fig/beagle.jpg'\n",
    "filenames = os.listdir('./googlenet/fig/')\n",
    "# print(filenames\n",
    "\n",
    "img = cv2.imread(filename)\n",
    "if img is None:\n",
    "    print('image read failed')\n",
    "    sys.exit()\n",
    "print(img.shape)\n",
    "\n",
    "model = './googlenet/bvlc_googlenet.caffemodel'\n",
    "config = './googlenet/deploy.prototxt'\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "if net.empty():\n",
    "    print('Network load failed')\n",
    "    sys.exit()\n",
    "print('Network load complete')\n",
    "\n",
    "classNames = []\n",
    "classfile = './googlenet/classification_classes_ILSVRC2012.txt'\n",
    "with open(classfile, 'r') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "print(len(classNames))\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (244,244), (104,117,12),\n",
    "                            swapRB = False)\n",
    "net.setInput(blob)\n",
    "prob = net.forward()\n",
    "# print(prob.shape)\n",
    "\n",
    "out = prob.flatten()\n",
    "# print(out.shape)\n",
    "classId = np.argmax(out)\n",
    "confidence = out[classId]\n",
    "category = classNames[classId]\n",
    "text = f'{category} ({confidence*100:4.2f} %)'\n",
    "cv2.putText(img, text, (10,30), cv2.FONT_HERSHEY_COMPLEX,\n",
    "           1, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "# print(classId)\n",
    "# print(classNames[classId])\n",
    "# print(out[classId])\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8878468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network load complete\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "imgs = os.listdir('./googlenet/fig/')\n",
    "# print(filenames)\n",
    "img_paths=[]\n",
    "for img in imgs:\n",
    "    path = './googlenet/fig/' + img\n",
    "    img_paths.append(path)\n",
    "# print(len(img_paths))\n",
    "# print(img_paths)\n",
    "\n",
    "model = './googlenet/bvlc_googlenet.caffemodel'\n",
    "config = './googlenet/deploy.prototxt'\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "if net.empty():\n",
    "    print('Network load failed')\n",
    "    sys.exit()\n",
    "print('Network load complete')\n",
    "\n",
    "classNames = []\n",
    "classfile = './googlenet/classification_classes_ILSVRC2012.txt'\n",
    "with open(classfile, 'r') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "print(len(classNames))\n",
    "\n",
    "cv2.namedWindow('img', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "idx=0\n",
    "while True:\n",
    "    img = cv2.imread(img_paths[idx])\n",
    "    if img is None:\n",
    "        print('image read failed')\n",
    "        sys.exit()\n",
    "#     print(img.shape)\n",
    "    img = cv2.resize(img, (500,500))\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(img, 1, (244,244), (104,117,12),\n",
    "                            swapRB = False)\n",
    "    net.setInput(blob)\n",
    "    prob = net.forward()\n",
    "# print(prob.shape)\n",
    "\n",
    "    out = prob.flatten()\n",
    "# print(out.shape)\n",
    "    classId = np.argmax(out)\n",
    "    confidence = out[classId]\n",
    "    category = classNames[classId]\n",
    "    text = f'{category} ({confidence*100:4.2f} %)'\n",
    "    cv2.putText(img, text, (10,490), cv2.FONT_HERSHEY_COMPLEX,\n",
    "               1, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1500)==27:\n",
    "        break\n",
    "        \n",
    "    idx +=1\n",
    "    if idx >= len(img_paths):\n",
    "        idx=0\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e5e80e",
   "metadata": {},
   "source": [
    "## face detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aba976c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./fig/sunglass.png')\n",
    "\n",
    "model = './face_detection/opencv_face_detector_uint8.pb'\n",
    "config = './face_detection/opencv_face_detector.pbtxt'\n",
    "\n",
    "face_detect_net = cv2.dnn.readNet(model, config)\n",
    "if face_detect_net.empty():\n",
    "    print('Network load error')\n",
    "    sys.exit()\n",
    "    \n",
    "blob = cv2.dnn.blobFromImage(img, 1, (300,300), (104,177,123),\n",
    "                            swapRB=False)\n",
    "face_detect_net.setInput(blob)\n",
    "out = face_detect_net.forward()\n",
    "detect = out[0,0,:,:]\n",
    "h,w = img.shape[:2]\n",
    "for i in range(detect.shape[0]):\n",
    "    confidence = detect[i, 2]\n",
    "    \n",
    "    if confidence > 0.5:\n",
    "        x1 = int(detect[i, 3]*w)\n",
    "        y1 = int(detect[i, 4]*h)\n",
    "        x2 = int(detect[i, 5]*w)\n",
    "        y2 = int(detect[i, 6]*h)\n",
    "        \n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "        text = 'Face: {:.2f}%'.format(confidence*100)\n",
    "        \n",
    "        cv2.putText(img,text, (x1,y1-2), cv2.FONT_HERSHEY_COMPLEX,\n",
    "                   0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "        \n",
    "    \n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "642dfb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = './face_detection/opencv_face_detector_uint8.pb'\n",
    "config = './face_detection/opencv_face_detector.pbtxt'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cap opened failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "net = cv2.dnn.readNet(model, config)\n",
    "if net.empty():\n",
    "    print(\"Network load failed\")\n",
    "    sys.exit()\n",
    "    \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"frame read failed\")\n",
    "        break\n",
    "        \n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300,300), (104,177,123))\n",
    "    net.setInput(blob)\n",
    "    out = net.forward()\n",
    "    detect = out[0,0,:,:]\n",
    "    h,w = frame.shape[:2]\n",
    "\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i,2]\n",
    "        if confidence >0.5:\n",
    "            x1 = int(detect[i, 3]*w)\n",
    "            y1 = int(detect[i, 4]*h)\n",
    "            x2 = int(detect[i, 5]*w)\n",
    "            y2 = int(detect[i, 6]*h)\n",
    "\n",
    "            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "            text = 'Face: {:.2f}%'.format(confidence*100)\n",
    "\n",
    "            cv2.putText(frame, text, (x1,y1-2), cv2.FONT_HERSHEY_COMPLEX,\n",
    "                       0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(30)==27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f302cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print('open failed')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02658f",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ff852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bf291",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)/255.\n",
    "x_test = x_test.reshape(-1,28,28,1)/255.\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(x_test.shape, x_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3,3),\n",
    "                             input_shape=(28,28,1),\n",
    "                             activation='relu'))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation=('relu')))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc242b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = './mnist_my_model/{epoch:002d}-{val_loss:.4f}.h5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=modelpath,\n",
    "    save_best_only=True,\n",
    "    verbose=True\n",
    ")\n",
    "stoppoint = keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=30, batch_size=200,\n",
    "                verbose=1, validation_split=0.3,\n",
    "                 callbacks=[checkpoint, stoppoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0385c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./mnist_onnx/', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8025390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf2onnx\n",
      "  Downloading tf2onnx-1.9.3-py3-none-any.whl (435 kB)\n",
      "Collecting onnx>=1.4.1\n",
      "  Downloading onnx-1.11.0-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "Requirement already satisfied: flatbuffers~=1.12 in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from tf2onnx) (1.12)\n",
      "Requirement already satisfied: numpy>=1.14.1 in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from tf2onnx) (1.22.3)\n",
      "Requirement already satisfied: requests in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from tf2onnx) (2.26.0)\n",
      "Requirement already satisfied: six in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from tf2onnx) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from onnx>=1.4.1->tf2onnx) (3.19.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from onnx>=1.4.1->tf2onnx) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from requests->tf2onnx) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from requests->tf2onnx) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from requests->tf2onnx) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mu-jun\\anaconda3\\lib\\site-packages (from requests->tf2onnx) (2.0.4)\n",
      "Installing collected packages: onnx, tf2onnx\n",
      "Successfully installed onnx-1.11.0 tf2onnx-1.9.3\n"
     ]
    }
   ],
   "source": [
    "# ! pip install -U tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m tf2onnx.convert --saved-model mnist_onnx --output model_mnist.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae1eb1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (97.37%)\n",
      "1 (99.93%)\n",
      "3 (59.62%)\n",
      "3 (88.62%)\n",
      "3 (52.03%)\n",
      "9 (67.59%)\n",
      "7 (99.86%)\n",
      "5 (48.86%)\n",
      "3 (48.03%)\n",
      "3 (45.53%)\n",
      "9 (45.85%)\n"
     ]
    }
   ],
   "source": [
    "def norm_digit(img):\n",
    "    # 무게 중심 좌표 추출\n",
    "    m = cv2.moments(img)\n",
    "    cx = m['m10'] / m['m00']\n",
    "    cy = m['m01'] / m['m00']\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # affine 행렬 생성\n",
    "    aff = np.array([[1, 0, w/2 - (cx + 0.5)], [0, 1, h/2 - (cy + 0.5)]], \n",
    "                   dtype=np.float32)\n",
    "    \n",
    "    # warpAffine을 이용해 기하학 변환\n",
    "    dst = cv2.warpAffine(img, aff, (0, 0))\n",
    "    return dst\n",
    "\n",
    "def on_mouse(event, x,y, flags, params):\n",
    "    global oldx, oldy\n",
    "    if event==cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x,y\n",
    "    elif event==cv2.EVENT_MOUSEMOVE:\n",
    "        if flags&cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.line(img, (oldx,oldy), (x,y), 255, 20, cv2.LINE_AA)\n",
    "            cv2.imshow('image', img)\n",
    "            oldx,oldy = x,y\n",
    "            \n",
    "            \n",
    "net = cv2.dnn.readNet('./model_mnist.onnx')\n",
    "if net.empty():\n",
    "    print('Network load failed')\n",
    "    sys.exit()\n",
    "\n",
    "img = np.zeros((400,400), np.uint8)\n",
    "cv2.imshow('image', img)\n",
    "cv2.setMouseCallback('image', on_mouse)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey()\n",
    "    if key==27:\n",
    "        break\n",
    "    elif key == ord(' '):\n",
    "        blob= cv2.dnn.blobFromImage(norm_digit(img), 1/255,(28,28))\n",
    "        net.setInput(blob)\n",
    "        prob = net.forward()\n",
    "        \n",
    "        _, maxVal, _, maxLoc = cv2.minMaxLoc(prob)\n",
    "        digit = maxLoc[0]\n",
    "        print(f'{digit} ({maxVal*100:4.2f}%)')\n",
    "        img.fill(0)\n",
    "        cv2.imshow('image',img)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd84aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc787214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
